
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8"> 
    <title>Alberto Gaona | Projects</title>
    
    <link href='../../img/icon.ico' rel='shortcut icon' type='image/ico'/>

    <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css">
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
    <script src="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/js/bootstrap.min.js"></script>

    <link rel="stylesheet" type="text/css" href="../../css/style.css" />

    <style type="text/css" media="screen">
        #trailer .modal-dialog {
            margin-top: 200px;
            width: 640px;
            height: 480px;
        }
        .hanging-close {
            position: absolute;
            top: -12px;
            right: -12px;
            z-index: 9001;
        }
        #trailer-video {
            width: 100%;
            height: 100%;
        }
        .movie-tile {
            margin-bottom: 10px;
            padding-top: 10px;
            padding-left: 0px;
            padding-right: 0px;
        }
        .movie-tile:hover {
            background-color: #EEE;
            cursor: pointer;
        }
        .scale-media {
            padding-bottom: 56.25%;
            position: relative;
        }
        .scale-media iframe {
            border: none;
            height: 100%;
            position: absolute;
            width: 100%;
            left: 0;
            top: 0;
            background-color: black;
        }

    </style>

    <script type="text/javascript" charset="utf-8">
        // Pause the video when the modal is closed
        $(document).on('click', '.hanging-close, .modal-backdrop, .modal', function (event) {
            // Remove the src so the player itself gets removed, as this is the only
            // reliable way to ensure the video stops playing in IE
            $("#trailer-video-container").empty();
        });
        // Start playing the video whenever the trailer modal is opened
        $(document).on('click', '.movie-tile', function (event) {
            var projectName = $(this).attr('project-name');
            var technicalDescription = $(this).attr('technical-description');
            var videoUrl = $(this).attr('video-url');


            //var trailerYouTubeId = $(this).attr('data-trailer-youtube-id')
            //var sourceUrl = 'http://www.youtube.com/embed/' + trailerYouTubeId + '?autoplay=1&html5=1';
            //var sourceUrl = 'https://player.vimeo.com/video/195152250';

            $("#trailer-video-container").empty().append($("<iframe></iframe>", {
              //'id': 'trailer-video',
              //'type': 'text-html',
              'src': sourceUrl,
              'width':'640',
              'height':'360',
              'frameborder': 0
            }));

            $('#technical-speech').empty().append($("<h1></h1>",{
                projectName
            }),$("<p></p>",{
                technicalDescription
            }));
        });
        // Animate in the movies when the page loads
        $(document).ready(function () {
          $('.movie-tile').hide().first().show("fast", function showNext() {
            $(this).next("div").show("fast", showNext);
          });
        });
    </script>
</head>

<body>
    <div class="modal" id="trailer">
        <div class="modal-dialog">
            <div class="modal-content" style="background-color: black; color: white" id="technical-speech">
                <a href="#" class="hanging-close" data-dismiss="modal" aria-hidden="true">
                    <img src="https://lh5.ggpht.com/v4-628SilF0HtHuHdu5EzxD7WRqOrrTIDi_MhEG6_qkNtUK5Wg7KPkofp_VJoF7RS2LhxwEFCO1ICHZlc-o_=s0#w=24&h=24"/>
                </a>
            </div>
        </div>
    </div>

    <div>
        <h1>Alberto Gaona</h1>
        <h2>Projects</h2>
    <div>
        
    <div class="container">
        <div class="row">
            
<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Mariya" 
technical-description="<div style='text-align: center;'>
						  		<video controls poster='./img/huicholdos.png'>
                                <source src='./img/Mariya.mp4' type='video/mp4'>
                                </video>
                          	 </div><br/><br/><p>

						  A Mexican project that opens a communication portal between an indigenous community and the rest of the world. The Wixarikas
						  erroneously known as Huicholes are part of a Mexican town. Globally known for their art: The Huichol art.<br/> <br/>

						  Do you know that every piece of art they create really tells a story? each bracelet, each table, each figure tells something 
						  about their culture. Those stories create an identity for them. Through their tales, which have passed from generation to 
						  generation, they create a heritage to encourage new generations to follow in the footsteps of their ancestors.<br/> <br/>

						  Apart from facing the possible disapperence of their sacred land due mining, day by day they face a problem that goes unnoticed:
						  'migration'. Being located in the highest part of the Sierra Madre Occidental, communication and access to new technologies is 
						  almost impossible. This force the new generations to migrate to the big cities, confronting the language problem that threatens 
						  the extinction of their native language.<br/> <br/>

						  The Mariya project tries to demonstrate that the technology is not fought with the ancestral customs of a town, giving the floor
						  to those who deserve to be heard, seeking to rescue their stories and knowledge which they consider sacred.<br/> <br/>

						  Fall in love with the Wixarika culture with the documentary: <a target='_blank' rel='noopener' href='https://huicholesfilm.com/en/'>
						  Huicholes the last peyote guardians</a>.
						  <br/>Learn more about the Mariya project by visiting the <a target='_blank' rel='noopener' href='https://proyectomariya.github.io/'>
						  official website</a>.<br/><br/>" 
video-url="https://player.vimeo.com/video/195152250" 
github-url="https://github.com/proyectomariya/translate"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>Mariya</h3>
    <h4>Taking advantage of technology and all available resources, we intend to put an end to the communication barrier between the Wixarica (Huicholes) community and the rest of the world, seeking to rescue their stories and knowledge which they consider sacred. Mariya is a translation device that seeks to save a Mexican culture.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Bike Share" 
technical-description="
						  Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and 
						  return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position
						  and return back in another position. Currently, there are about over 500 bike-sharing programs around the world 
						  which is composed of over 500 thousands bicycles.<br/><br/>

						  This project is a simple neural network to make predictions of bike-sharing usage. Using a 
						  <a target='_blank' rel='noopener' href='https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset'>dataset</a> that 
						  has the number of riders for each hour of each day from January 1, 2011 to December 31, 2012. The data is pretty complicated. 
						  The weekends have lower over all rideship and there are spikes when people are biking to and from work during the week.
						  Also have information about temperature, humidity, and windspeed. all of these likely affecting the number of riders.<br/><br/>

						  The network has two layers, a hidden layer and an output layer. The hidden layer use the sigmoid function for activations.
						  The output layer has only one node and is used for regression, the output node is the same as the input node.<br/><br/>

						  In the following graph we can compare our predictions with the actual data:
						  <br/><br/>
						  <div style='text-align: center;'>
						  	<img src='./img/bikeshare-graph.png' alt='Bike share results'>
						  </div><br/><br/>
						  " 
video-url="" 
github-url="https://github.com/betogaona7/Deep-Learning/tree/master/DLNF-BikeShare"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/r5ULIvOOtdIWs/giphy.gif" width="370" height="250" >
    <h3>Bike Share</h3>
    <h4>Imagine yourself owning of a bike sharing company like CycleHop and you want to predict how many bikes you need because if you have too few you're losing money from potential riders or vice versa if you have too many you're wasting money on bikes that are just sitting around. This project predict the number of bikeshare users on a given day from historical data, so you can know how many bikes you will need in the near future.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Sign Language Recognizer" 
technical-description="
						  The overall goal of this project was to built a word recognizer for American Sign Language video sequences, demonstrating
						  the power of probabilistic models. In particular, this project employs Hidden Marcov Models (HMMs)  that use a preprocessed
						  <a target='_blank' rel='noopener' href='http://www-i6.informatik.rwth-aachen.de/%7Edreuw/database-rwth-boston-104.php'>dataset</a> 
						  of tracked hand and nose positions extracted from video to identify individual words from test sequences.<br/><br/>

						  The next video is an example of how the hand locations are tracked:<br/><br/></p>
						  
						  <div style='text-align: center;'>
						  	<video controls>
						      	<source src='./img/Recognizer.mp4' type='video/mp4'>
						    </video>
						  </div><br/><br/><p>
						  
						  I experimented with four feature sets and three model selection methods (that is 12 possible combinations). The best combination
						  was features-ground (those are differences between hand and nose locations) with Selector CV (Log likelihood with Cross-validation folds) 
						  that gets a Word Error Rate (WER) of 53%. This can be improved by adding techniques like Context training, Statistical Grammar, 
						  State typing, Segmentally Boosted HMMs and probably many more that will help us obtain even lower WER.<br/><br/>
						  " 
video-url="" 
github-url="https://github.com/betogaona7/AI-projects/tree/master/AIND-Recognizer"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>Sign Language Recognizer</h3>
    <h4>According to the World Health Organization (WHO) 360 millon people worldwide have disabling hearing loss of which 70 million people use sign language as their first language. Now, how many interpreters are there? much less than half. In this project I built a system that can recognize words communicated using the American Sign Language (ASL).</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Air Cargo Planner" 
technical-description="
						  In this project I defined a group of problems in classical PDDL (Planning Domain Definition Language) that use
						  a planning search agent to solve deterministic logistics problems for an Air Cargo transport system. For example
						  the next problem:</br></br></p>

						  <div style='text-align: center;'>
						  	<img src='./img/planner-problem.png' alt='Planner problem'>
						  </div><br/><br/><p>

						  Then setup the problems for search of two types: Non-heuristic searches and Heuristic searches. The non-heuristic
						  searches include Breadth-First search (BFS), Depth-First graph search (DFS) and Uniform-Cost search (UCS). Of them the most
						  efficient was the UCS algorithm.</br></br>

						  For the heuristic searches I used the A star algorithm (A*) with two different heuristics:</br></p>
						  <ul type='disk'>
						  	<li><p>Ignore preconditions heuristic - The minimum number of actions that must be carried out from the current state in order 
						  	to satisfy all of the goal conditions by ignoring the preconditions required for an action to be executed.</p></li>
						  	<li><p>Level sum heuristic - The sum of level costs of the individual goals (admissible if goals independent).</p></li>
						  </ul></br><p>
						  A* with ignore preconditions heuristic was the one that works best. The following image is the answer to the problem
						  posed in the previous image solved by both algorithms (A* and UCS):<br/><br/></p>

						  <div style='text-align: center;'>
						  	<img class='planner' src='./img/planner-solution.png' alt='Planner solution'>
						  </div><br/><br/><p>

						  UCS takes 157 seconds to solve it while A* only takes 30 seconds. That is one of the great advantages of using 
						  heuristics.<br/><br/>
						  " 
video-url="" 
github-url="https://github.com/betogaona7/AI-projects/tree/master/AIND-Planning"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>Air Cargo Planner</h3>
    <h4>Have you asked yourself how companies like DHL schedule all their shipments?, This project solves a group of problems for an Air Cargo transport system using a planning search agent, in which we see how an agent take advantage of the structure of a problem to construct a complex plan of action.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="TV Scripts Generator" 
technical-description="
						  This project generates Simpsons TV scripts. Specifically for a scene in the Moes tavern, using a Recurrent Neural Network (RNN) 
						  that was trained with a subset of the <a target='_blank' rel='noopener' href='https://www.kaggle.com/wcukierski/the-simpsons-by-the-data'>
						  Simpsons dataset </a> of scripts from 27 seasons. For example: <br/><br/></p>
						  <div style='text-align: center;'>
						  	<img src='./img/scripts-script.png' alt='Simpson script'>
						  </div><br/><br/><p>
						  It is okey if the TV script does not make much sense. The network was trained on less than a megabyte of text. In order to improve
						  results we need to use a smaller voacabulary or get more data. Luckly there is more data! As mentioned in the beginning, this is 
						  a subset of another database. Train on all the data would take too long. <br/><br/>
						  " 
video-url="" 
github-url="https://github.com/betogaona7/Deep-Learning/tree/master/DLNF-Scripts"
data-toggle="modal" data-target="#trailer">
    <img src="http://media3.giphy.com/media/kEKcOWl8RMLde/giphy.gif" width="370" height="250" >
    <h3>TV Scripts Generator</h3>
    <h4>The way to write a script for a TV show is to actually write a script. A pen is useful, typing is also good. Keep putting words on the page, but if for some reason you don't feel good, you're sick or you just feel stuck, try to use a computer that writes it for you. This project generates an original piece of writing after being trained using your existing scripts, therefore, the new piece will conserve your own writing style.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="New Faces Generator" 
technical-description="
						  This is a Generative Adversarial Network (GAN) that use the 
						  <a target='_blank' rel='noopener' href='http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html'>CelebFaces Attributes dataset (CelebA)</a> 
						  consisting of more than 200,000 of celebrity images with annotations as training to generate new images of faces.<br/><br/>

						  GANs are used for generating realistic data. The word adversarial in Generative Adversarial Networks means that we have two networks,
						  the generator and the discriminator which are in a competition with each other. The generator wants to minimize the value function 
						  and the discriminator wants to maximize the value function.<br/><br/> 

						  We can think of this process as being like a competition between counterfeiters and police. The generator net is like a group of
						  counterfeiters trying to produce fake money and pass it off as real. The police try to catch counterfeiters using fake money but
						  still want to let everyone else spend their real money. Over time the police get better at detecting counterfeit money and the 
						  conterfeiters get better at faking it. Eventually the counterfeiters are forced to make perfect replicas of real money.<br/><br/>

						  When we train a GAN on the CelebA dataset we can watch it being generating random images, gradually learn to generate faces. That is 
						  the basic idea of how GANs work.<br/><br/>

						  In the project CelebA images were cropped to remove parts of the image that do not include a face, then resized down to 28x28 pixels. 
						  The following image is an example of how the generated faces look.<br/><br/></p>

						  <div style='text-align: center;'>
						  	<img src='./img/faces-example.png' alt='Faces'>
						  </div><br/><br/><p>

						  Note that some faces look like horror movie characters!<br/><br/>
						  " 
video-url="" 
github-url="https://github.com/betogaona7/Deep-Learning/tree/master/DLNF-Faces"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>New Faces Generator</h3>
    <h4>Imagine you work for a movie production company, and your job is to design the characters in a movie. You would usually draw a bunch of different concepts before arriving at the final design. What if you had a program that could do this for you?. This project generate new faces using celebrity images.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="The Isolation Game" 
technical-description="Technical description not available yet -" 
video-url="" 
github-url="https://github.com/betogaona7/AI-projects/tree/master/AIND-Isolation"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>The Isolation Game</h3>
    <h4>Isolation is a two-player game in which the players alternate turns moving a single piece from one cell to another on a board. Whenever either player occupies a cell, the cell becomes blocked for the remainder of the game. The first player with no remaining legal moves loses, and the opponent is declared the winner. In this version each player is restricted to L-shaped movements on a 7x7 board. This project is a game-playing agent to win the isolation game.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="The Sudoku Puzzle" 
technical-description="Technical description not available yet -" 
video-url="" 
github-url="https://github.com/betogaona7/AI-projects/tree/master/AIND-Sudoku"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/TGHMbONT5eGgU/giphy.gif" width="370" height="250" >
    <h3>The Sudoku Puzzle</h3>
    <h4>Surely you have played Sudoku at least once in your life, Sudoku is that puzzle game that comes in magazines, newspapers, etc. The goal is to fill a 9x9 grid with digits so that each column, each row, and each of the nine 3x3 subgrids that compose the grid contains all of the digits from 1 to 9. Have you ever been stuck trying to solve one?. This project is a play-game agent for solve diagonal sudoku puzzles.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Image Classification" 
technical-description="Technical description not available yet -" 
video-url="" 
github-url="https://github.com/betogaona7/Deep-Learning/tree/master/DLNF-Classification"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/PnabT7xYZ3ffG/giphy.gif" width="370" height="250" >
    <h3>Image Classification</h3>
    <h4>Vision is the main way humans gain information about the world, with the passage of time we have been able to give eyes to the machines, from that, amazing applications have been created. For example, a company called Orbital Insigths analyze satellite imagery to count cars and oil tank levels automatically to predict such things as mall sales and oil production. In this project I developed a program capable of recognize and classify ten different types of images.</h4>
    <h5>Read more...</h5>
</div>

<div class="col-md-6 col-lg-4 movie-tile text-center size" 
project-name="Machine Translation" 
technical-description="Technical description not available yet -" 
video-url="" 
github-url="https://github.com/betogaona7/Deep-Learning/tree/master/DLNF-Translation"
data-toggle="modal" data-target="#trailer">
    <img src="https://media.giphy.com/media/tu54GM19sqJOw/giphy.gif" width="370" height="250" >
    <h3>Machine Translation</h3>
    <h4>Language is the backbone of our civilitation. Without written records of previous scientific discoveries, we could never accomplish great events like traveling to space. We've accomplish a lot in the world where 13 of the most common languages are natively spoken by less than 50 percent of the population. What would the world be like if we could all work together without a language barrier?. This project is an English to French translator.</h4>
    <h5>Read more...</h5>
</div>

        </div>
    </div>

    <footer class="footer">
        <div class="inner-container">
            <ul class="footer-links">
                <li><a href="http://www.facebook.com/betogaona07" target="_blank" rel="noopener"> Facebook </a></li>
                <li><a href="http://www.github.com/betogaona7" target="_blank" rel="noopener"> Github </a></li>
                <li><a href="http://www.instagram.com/betogaona7" target="_blank" rel="noopener"> Instagram </a></li>
                <li><a href="http://www.instagram.com/betogaona7" target="_blank" rel="noopener"> Blog </a></li>
            </ul>
        </div>

        <div class="footer-copy">
            2018 Alberto Gaona - <a href="mailto:albertoo_3c@hotmail.com"> Contact </a>
        </div>
    </footer>
</body>
</html>
